{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer-to-Peer (P2P) with 2x NVIDIA 4090 RTX\n",
    "\n",
    "- cloud provider: [runpod.io](https://www.runpod.io/)\n",
    "- pod: 2 x RTX 4090 (25 vCPU 200 GB RAM)\n",
    "- image: `runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 27 13:54:37 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.154.05             Driver Version: 535.154.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  | 00000000:02:00.0 Off |                  Off |\n",
      "| 30%   27C    P8              21W / 450W |      1MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        On  | 00000000:42:00.0 Off |                  Off |\n",
      "| 30%   25C    P8              19W / 450W |      1MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\u001b[4mGPU0\tGPU1\tCPU Affinity\tNUMA Affinity\tGPU NUMA ID\u001b[0m\n",
      "GPU0\t X \tSYS\t0-63\t0\t\tN/A\n",
      "GPU1\tSYS\t X \t0-63\t0\t\tN/A\n",
      "\n",
      "Legend:\n",
      "\n",
      "  X    = Self\n",
      "  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)\n",
      "  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node\n",
      "  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\n",
      "  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)\n",
      "  PIX  = Connection traversing at most a single PCIe bridge\n",
      "  NV#  = Connection traversing a bonded set of # NVLinks\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi topo -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building [nccl-tests](https://github.com/NVIDIA/nccl-tests/tree/master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nccl-tests'...\n",
      "remote: Enumerating objects: 337, done.\u001b[K\n",
      "remote: Counting objects: 100% (215/215), done.\u001b[K\n",
      "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
      "remote: Total 337 (delta 184), reused 140 (delta 132), pack-reused 122\u001b[K\n",
      "Receiving objects: 100% (337/337), 129.26 KiB | 1.38 MiB/s, done.\n",
      "Resolving deltas: 100% (223/223), done.\n",
      "make -C src build BUILDDIR=/workspace/p2p-4090/nccl-tests/build\n",
      "make[1]: Entering directory '/workspace/p2p-4090/nccl-tests/src'\n",
      "Compiling  timer.cc                            > /workspace/p2p-4090/nccl-tests/build/timer.o\n",
      "Compiling /workspace/p2p-4090/nccl-tests/build/verifiable/verifiable.o\n",
      "Compiling  all_reduce.cu                       > /workspace/p2p-4090/nccl-tests/build/all_reduce.o\n",
      "Compiling  common.cu                           > /workspace/p2p-4090/nccl-tests/build/common.o\n",
      "Linking  /workspace/p2p-4090/nccl-tests/build/all_reduce.o > /workspace/p2p-4090/nccl-tests/build/all_reduce_perf\n",
      "Compiling  all_gather.cu                       > /workspace/p2p-4090/nccl-tests/build/all_gather.o\n",
      "Linking  /workspace/p2p-4090/nccl-tests/build/all_gather.o > /workspace/p2p-4090/nccl-tests/build/all_gather_perf\n",
      "Compiling  broadcast.cu                        > /workspace/p2p-4090/nccl-tests/build/broadcast.o\n",
      "Linking  /workspace/p2p-4090/nccl-tests/build/broadcast.o > /workspace/p2p-4090/nccl-tests/build/broadcast_perf\n",
      "Compiling  reduce_scatter.cu                   > /workspace/p2p-4090/nccl-tests/build/reduce_scatter.o\n",
      "Linking  /workspace/p2p-4090/nccl-tests/build/reduce_scatter.o > /workspace/p2p-4090/nccl-tests/build/reduce_scatter_perf\n",
      "Compiling  reduce.cu                           > /workspace/p2p-4090/nccl-tests/build/reduce.o\n",
      "Linking  /workspace/p2p-4090/nccl-tests/build/reduce.o > /workspace/p2p-4090/nccl-tests/build/reduce_perf\n",
      "Compiling  alltoall.cu                         > /workspace/p2p-4090/nccl-tests/build/alltoall.o\n",
      "Linking  /workspace/p2p-4090/nccl-tests/build/alltoall.o > /workspace/p2p-4090/nccl-tests/build/alltoall_perf\n",
      "Compiling  scatter.cu                          > /workspace/p2p-4090/nccl-tests/build/scatter.o\n",
      "Linking  /workspace/p2p-4090/nccl-tests/build/scatter.o > /workspace/p2p-4090/nccl-tests/build/scatter_perf\n",
      "Compiling  gather.cu                           > /workspace/p2p-4090/nccl-tests/build/gather.o\n",
      "Linking  /workspace/p2p-4090/nccl-tests/build/gather.o > /workspace/p2p-4090/nccl-tests/build/gather_perf\n",
      "Compiling  sendrecv.cu                         > /workspace/p2p-4090/nccl-tests/build/sendrecv.o\n",
      "Linking  /workspace/p2p-4090/nccl-tests/build/sendrecv.o > /workspace/p2p-4090/nccl-tests/build/sendrecv_perf\n",
      "Compiling  hypercube.cu                        > /workspace/p2p-4090/nccl-tests/build/hypercube.o\n",
      "Linking  /workspace/p2p-4090/nccl-tests/build/hypercube.o > /workspace/p2p-4090/nccl-tests/build/hypercube_perf\n",
      "make[1]: Leaving directory '/workspace/p2p-4090/nccl-tests/src'\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/nccl-tests.git && cd nccl-tests/ && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running all_reduce_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# nThread 1 nGpus 2 minBytes 8 maxBytes 134217728 step: 2(factor) warmup iters: 5 iters: 20 agg iters: 1 validation: 1 graph: 0\n",
      "#\n",
      "# Using devices\n",
      "#  Rank  0 Group  0 Pid  10358 on 252630d85675 device  0 [0x02] NVIDIA GeForce RTX 4090\n",
      "#  Rank  1 Group  0 Pid  10358 on 252630d85675 device  1 [0x42] NVIDIA GeForce RTX 4090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "#                                                              out-of-place                       in-place          \n",
      "#       size         count      type   redop    root     time   algbw   busbw #wrong     time   algbw   busbw #wrong\n",
      "#        (B)    (elements)                               (us)  (GB/s)  (GB/s)            (us)  (GB/s)  (GB/s)       \n",
      "           8             2     float     sum      -1     7.50    0.00    0.00      0     7.46    0.00    0.00      0\n",
      "          16             4     float     sum      -1     7.42    0.00    0.00      0     7.55    0.00    0.00      0\n",
      "          32             8     float     sum      -1     7.36    0.00    0.00      0     7.41    0.00    0.00      0\n",
      "          64            16     float     sum      -1     7.36    0.01    0.01      0     7.52    0.01    0.01      0\n",
      "         128            32     float     sum      -1     7.42    0.02    0.02      0     7.35    0.02    0.02      0\n",
      "         256            64     float     sum      -1     7.63    0.03    0.03      0     7.72    0.03    0.03      0\n",
      "         512           128     float     sum      -1     8.17    0.06    0.06      0     8.25    0.06    0.06      0\n",
      "        1024           256     float     sum      -1     8.31    0.12    0.12      0     8.29    0.12    0.12      0\n",
      "        2048           512     float     sum      -1     8.44    0.24    0.24      0     8.27    0.25    0.25      0\n",
      "        4096          1024     float     sum      -1     8.74    0.47    0.47      0     8.55    0.48    0.48      0\n",
      "        8192          2048     float     sum      -1    10.36    0.79    0.79      0    10.13    0.81    0.81      0\n",
      "       16384          4096     float     sum      -1    13.79    1.19    1.19      0    14.11    1.16    1.16      0\n",
      "       32768          8192     float     sum      -1    20.96    1.56    1.56      0    20.58    1.59    1.59      0\n",
      "       65536         16384     float     sum      -1    34.25    1.91    1.91      0    33.94    1.93    1.93      0\n",
      "      131072         32768     float     sum      -1    49.57    2.64    2.64      0    50.38    2.60    2.60      0\n",
      "      262144         65536     float     sum      -1    83.25    3.15    3.15      0    83.80    3.13    3.13      0\n",
      "      524288        131072     float     sum      -1    131.5    3.99    3.99      0    133.9    3.92    3.92      0\n",
      "     1048576        262144     float     sum      -1    257.7    4.07    4.07      0    258.7    4.05    4.05      0\n",
      "     2097152        524288     float     sum      -1    492.0    4.26    4.26      0    498.7    4.21    4.21      0\n",
      "     4194304       1048576     float     sum      -1    955.1    4.39    4.39      0    956.1    4.39    4.39      0\n",
      "     8388608       2097152     float     sum      -1   1907.7    4.40    4.40      0   1907.4    4.40    4.40      0\n",
      "    16777216       4194304     float     sum      -1   3812.1    4.40    4.40      0   3821.6    4.39    4.39      0\n",
      "    33554432       8388608     float     sum      -1   7656.3    4.38    4.38      0   7662.8    4.38    4.38      0\n",
      "    67108864      16777216     float     sum      -1    15601    4.30    4.30      0    15627    4.29    4.29      0\n",
      "   134217728      33554432     float     sum      -1    32399    4.14    4.14      0    32393    4.14    4.14      0\n",
      "# Out of bounds values : 0 OK\n",
      "# Avg bus bandwidth    : 2.01835 \n",
      "#\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nccl-tests/build/all_reduce_perf -b 8 -e 128M -f 2 -g 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0->cuda:1: 20.989 GB/s\n",
      "cuda:1->cuda:0: 20.932 GB/s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "device0 = torch.device(\"cuda\", 0)\n",
    "device1 = torch.device(\"cuda\", 1)\n",
    "\n",
    "x0 = torch.randn(1024, 1024, 1024, dtype=torch.float32, device=device0)\n",
    "x1 = torch.randint(0,100, (1024, 1024, 1024), dtype=torch.long, device=device1)\n",
    "\n",
    "def copy_tensor(x, dest_device):\n",
    "    y = x.to(dest_device, non_blocking=False, copy=False)\n",
    "    return y\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt='copy_tensor(x0, device1)',\n",
    "    setup='from __main__ import copy_tensor',\n",
    "    globals={'x0': x0, 'device1': device1},\n",
    "    num_threads=1)\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='copy_tensor(x1, device1)',\n",
    "    setup='from __main__ import copy_tensor',\n",
    "    globals={'x1': x1, 'device1': device0},\n",
    "    num_threads=1)\n",
    "\n",
    "# sanity check\n",
    "s0 = x0.sum().cpu()\n",
    "y1 = copy_tensor(x0, device1)\n",
    "s1 = y1.sum().cpu()\n",
    "assert torch.abs(s0-s1) < 1e-5\n",
    "\n",
    "m0 = t0.timeit(100)\n",
    "storage_size0 = x0.untyped_storage().size()\n",
    "print(f\"{device0}->{device1}: {storage_size0/m0.mean/2**30:.3f} GB/s\")\n",
    "\n",
    "m1 = t1.timeit(100)\n",
    "storage_size1 = x1.untyped_storage().size()\n",
    "print(f\"{device1}->{device0}: {storage_size1/m1.mean/2**30:.3f} GB/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank=1 recv N=50, elapsed_time=50.4978s, 3.961 GB/s, sum=-75526.25 (cuda:1)\n",
      "rank=0 send N=50, elapsed_time=50.4978s, 3.961 GB/s, sum=-75526.25 (cuda:0)\n",
      "rank=0 broadcast(a, src=0) N=50, elapsed_time=50.1422s, 3.989 GB/s, sum=-75526.25 (cuda:0)\n",
      "rank=1 broadcast(a, src=0) N=50, elapsed_time=50.1425s, 3.989 GB/s, sum=-75526.25 (cuda:1)\n",
      "rank=1 broadcast(a, src=1) N=50, elapsed_time=50.3260s, 3.974 GB/s, sum=-75526.25 (cuda:1)\n",
      "rank=0 broadcast(a, src=1) N=50, elapsed_time=50.3260s, 3.974 GB/s, sum=-75526.25 (cuda:0)\n"
     ]
    }
   ],
   "source": [
    "!OMP_NUM_THREADS=1 torchrun --standalone --nnodes=1 --nproc-per-node 2 torch_distributed_nccl_test.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
