{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peer-to-Peer (P2P) with 2x RTX 4000 Ada   \n",
    "\n",
    "- cloud provider: [runpod.io](https://www.runpod.io/)\n",
    "- pod: 2 x RTX 4000 Ada (19 vCPU 100 GB RAM)\n",
    "- image: `runpod/pytorch:2.2.0-py3.10-cuda12.1.1-devel-ubuntu22.04`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 27 22:31:29 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX 4000 Ada Gene...    On  | 00000000:82:00.0 Off |                  Off |\n",
      "| 30%   30C    P8              11W / 130W |      2MiB / 20475MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX 4000 Ada Gene...    On  | 00000000:C1:00.0 Off |                  Off |\n",
      "| 30%   29C    P8              10W / 130W |      2MiB / 20475MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\u001b[4mGPU0\tGPU1\tCPU Affinity\tNUMA Affinity\tGPU NUMA ID\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU0\t X \tSYS\t0-47\t\tN/A\t\tN/A\n",
      "GPU1\tSYS\t X \t0-47\t\tN/A\t\tN/A\n",
      "\n",
      "Legend:\n",
      "\n",
      "  X    = Self\n",
      "  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)\n",
      "  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node\n",
      "  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)\n",
      "  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)\n",
      "  PIX  = Connection traversing at most a single PCIe bridge\n",
      "  NV#  = Connection traversing a bonded set of # NVLinks\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi topo -m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building [nccl-tests](https://github.com/NVIDIA/nccl-tests/tree/master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nccl-tests'...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 337, done.\u001b[K\n",
      "remote: Counting objects: 100% (215/215), done.\u001b[K\n",
      "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
      "remote: Total 337 (delta 184), reused 140 (delta 132), pack-reused 122\u001b[K\n",
      "Receiving objects: 100% (337/337), 129.29 KiB | 1.56 MiB/s, done.\n",
      "Resolving deltas: 100% (223/223), done.\n",
      "make -C src build BUILDDIR=/root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build\n",
      "make[1]: Entering directory '/root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/src'\n",
      "Compiling  timer.cc                            > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/timer.o\n",
      "Compiling /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/verifiable/verifiable.o\n",
      "Compiling  all_reduce.cu                       > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/all_reduce.o\n",
      "Compiling  common.cu                           > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/common.o\n",
      "Linking  /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/all_reduce.o > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/all_reduce_perf\n",
      "Compiling  all_gather.cu                       > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/all_gather.o\n",
      "Linking  /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/all_gather.o > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/all_gather_perf\n",
      "Compiling  broadcast.cu                        > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/broadcast.o\n",
      "Linking  /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/broadcast.o > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/broadcast_perf\n",
      "Compiling  reduce_scatter.cu                   > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/reduce_scatter.o\n",
      "Linking  /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/reduce_scatter.o > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/reduce_scatter_perf\n",
      "Compiling  reduce.cu                           > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/reduce.o\n",
      "Linking  /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/reduce.o > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/reduce_perf\n",
      "Compiling  alltoall.cu                         > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/alltoall.o\n",
      "Linking  /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/alltoall.o > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/alltoall_perf\n",
      "Compiling  scatter.cu                          > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/scatter.o\n",
      "Linking  /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/scatter.o > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/scatter_perf\n",
      "Compiling  gather.cu                           > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/gather.o\n",
      "Linking  /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/gather.o > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/gather_perf\n",
      "Compiling  sendrecv.cu                         > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/sendrecv.o\n",
      "Linking  /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/sendrecv.o > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/sendrecv_perf\n",
      "Compiling  hypercube.cu                        > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/hypercube.o\n",
      "Linking  /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/hypercube.o > /root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/build/hypercube_perf\n",
      "make[1]: Leaving directory '/root/p2p-perf/rtx-A4000-ada-2x/nccl-tests/src'\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/nccl-tests.git && cd nccl-tests/ && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running all_reduce_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# nThread 1 nGpus 2 minBytes 8 maxBytes 134217728 step: 2(factor) warmup iters: 5 iters: 20 agg iters: 1 validation: 1 graph: 0\n",
      "#\n",
      "# Using devices\n",
      "#  Rank  0 Group  0 Pid   2858 on 49a30927f3aa device  0 [0x82] NVIDIA RTX 4000 Ada Generation\n",
      "#  Rank  1 Group  0 Pid   2858 on 49a30927f3aa device  1 [0xc1] NVIDIA RTX 4000 Ada Generation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "#                                                              out-of-place                       in-place          \n",
      "#       size         count      type   redop    root     time   algbw   busbw #wrong     time   algbw   busbw #wrong\n",
      "#        (B)    (elements)                               (us)  (GB/s)  (GB/s)            (us)  (GB/s)  (GB/s)       \n",
      "           8             2     float     sum      -1     9.74    0.00    0.00      0     9.51    0.00    0.00      0\n",
      "          16             4     float     sum      -1     9.32    0.00    0.00      0     9.34    0.00    0.00      0\n",
      "          32             8     float     sum      -1     9.39    0.00    0.00      0     9.28    0.00    0.00      0\n",
      "          64            16     float     sum      -1     9.37    0.01    0.01      0     9.32    0.01    0.01      0\n",
      "         128            32     float     sum      -1     9.39    0.01    0.01      0     9.30    0.01    0.01      0\n",
      "         256            64     float     sum      -1     9.37    0.03    0.03      0     9.32    0.03    0.03      0\n",
      "         512           128     float     sum      -1     9.37    0.05    0.05      0     9.35    0.05    0.05      0\n",
      "        1024           256     float     sum      -1     9.41    0.11    0.11      0     9.54    0.11    0.11      0\n",
      "        2048           512     float     sum      -1     9.51    0.22    0.22      0     9.52    0.22    0.22      0\n",
      "        4096          1024     float     sum      -1     9.57    0.43    0.43      0    10.12    0.40    0.40      0\n",
      "        8192          2048     float     sum      -1    11.37    0.72    0.72      0    10.04    0.82    0.82      0\n",
      "       16384          4096     float     sum      -1    10.72    1.53    1.53      0    10.71    1.53    1.53      0\n",
      "       32768          8192     float     sum      -1    12.29    2.67    2.67      0    12.93    2.53    2.53      0\n",
      "       65536         16384     float     sum      -1    18.29    3.58    3.58      0    18.28    3.59    3.59      0\n",
      "      131072         32768     float     sum      -1    36.38    3.60    3.60      0    36.62    3.58    3.58      0\n",
      "      262144         65536     float     sum      -1    48.49    5.41    5.41      0    48.20    5.44    5.44      0\n",
      "      524288        131072     float     sum      -1    70.39    7.45    7.45      0    66.80    7.85    7.85      0\n",
      "     1048576        262144     float     sum      -1    100.1   10.48   10.48      0    88.99   11.78   11.78      0\n",
      "     2097152        524288     float     sum      -1    148.2   14.15   14.15      0    146.1   14.35   14.35      0\n",
      "     4194304       1048576     float     sum      -1    244.3   17.17   17.17      0    237.2   17.69   17.69      0\n",
      "     8388608       2097152     float     sum      -1    446.9   18.77   18.77      0    437.2   19.19   19.19      0\n",
      "    16777216       4194304     float     sum      -1    852.3   19.68   19.68      0    842.6   19.91   19.91      0\n",
      "    33554432       8388608     float     sum      -1   1676.5   20.01   20.01      0   1678.4   19.99   19.99      0\n",
      "    67108864      16777216     float     sum      -1   3337.2   20.11   20.11      0   3334.8   20.12   20.12      0\n",
      "   134217728      33554432     float     sum      -1   6660.3   20.15   20.15      0   6643.3   20.20   20.20      0\n",
      "# Out of bounds values : 0 OK\n",
      "# Avg bus bandwidth    : 6.71499 \n",
      "#\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nccl-tests/build/all_reduce_perf -b 8 -e 128M -f 2 -g 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0->cuda:1: 24.545 GB/s\n",
      "cuda:1->cuda:0: 24.488 GB/s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "device0 = torch.device(\"cuda\", 0)\n",
    "device1 = torch.device(\"cuda\", 1)\n",
    "\n",
    "x0 = torch.randn(1024, 1024, 1024, dtype=torch.float32, device=device0)\n",
    "x1 = torch.randint(0,100, (1024, 1024, 1024), dtype=torch.long, device=device1)\n",
    "\n",
    "def copy_tensor(x, dest_device):\n",
    "    y = x.to(dest_device, non_blocking=False, copy=False)\n",
    "    return y\n",
    "\n",
    "t0 = benchmark.Timer(\n",
    "    stmt='copy_tensor(x0, device1)',\n",
    "    setup='from __main__ import copy_tensor',\n",
    "    globals={'x0': x0, 'device1': device1},\n",
    "    num_threads=1)\n",
    "\n",
    "t1 = benchmark.Timer(\n",
    "    stmt='copy_tensor(x1, device1)',\n",
    "    setup='from __main__ import copy_tensor',\n",
    "    globals={'x1': x1, 'device1': device0},\n",
    "    num_threads=1)\n",
    "\n",
    "# sanity check\n",
    "s0 = x0.sum().cpu()\n",
    "y1 = copy_tensor(x0, device1)\n",
    "s1 = y1.sum().cpu()\n",
    "assert torch.abs(s0-s1) < 1e-5\n",
    "\n",
    "m0 = t0.timeit(100)\n",
    "storage_size0 = x0.untyped_storage().size()\n",
    "print(f\"{device0}->{device1}: {storage_size0/m0.mean/2**30:.3f} GB/s\")\n",
    "\n",
    "m1 = t1.timeit(100)\n",
    "storage_size1 = x1.untyped_storage().size()\n",
    "print(f\"{device1}->{device0}: {storage_size1/m1.mean/2**30:.3f} GB/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank=0 send N=50, elapsed_time=9.6049s, 20.823 GB/s, sum=-49910.9375 (cuda:0)\n",
      "rank=1 recv N=50, elapsed_time=9.6050s, 20.823 GB/s, sum=-49910.9375 (cuda:1)\n",
      "rank=0 broadcast(a, src=0) N=50, elapsed_time=10.6061s, 18.857 GB/s, sum=-49910.9375 (cuda:0)\n",
      "rank=0 broadcast(a, src=1) N=50, elapsed_time=10.5242s, 19.004 GB/s, sum=-49910.9375 (cuda:0)\n"
     ]
    }
   ],
   "source": [
    "!OMP_NUM_THREADS=1 /usr/local/bin/torchrun --standalone --nnodes=1 --nproc-per-node 2 torch_distributed_nccl_test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0+cu121'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
